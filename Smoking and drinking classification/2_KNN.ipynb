{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Содержание\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Создание и обучение модели](#3)\n",
    "    - [Подготовка данных для обучения](#31)\n",
    "    - [Обучение моделей](#33)\n",
    "        - [Метод к-ближайших соседей](#331)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание и обучение модели <a id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом шаге происходит обучение модели. Обучение моделей машинного обучения происходит итерационно - пробуются различные модели, перебираются гиперпараметры, сравниваются значения выбранной метрики и выбирается лучшая комбинация.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_dataset.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>waistline</th>\n",
       "      <th>sight_left</th>\n",
       "      <th>sight_right</th>\n",
       "      <th>hear_left</th>\n",
       "      <th>hear_right</th>\n",
       "      <th>SBP</th>\n",
       "      <th>...</th>\n",
       "      <th>LDL_chole</th>\n",
       "      <th>triglyceride</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>urine_protein</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>SGOT_AST</th>\n",
       "      <th>SGOT_ALT</th>\n",
       "      <th>gamma_GTP</th>\n",
       "      <th>SMK_stat_type_cd</th>\n",
       "      <th>DRK_YN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>170</td>\n",
       "      <td>75</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>126</td>\n",
       "      <td>92</td>\n",
       "      <td>17.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>148</td>\n",
       "      <td>121</td>\n",
       "      <td>15.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>165</td>\n",
       "      <td>75</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>104</td>\n",
       "      <td>15.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>47</td>\n",
       "      <td>32</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>106</td>\n",
       "      <td>17.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>165</td>\n",
       "      <td>60</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>104</td>\n",
       "      <td>13.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  age  height  weight  waistline  sight_left  sight_right  hear_left  \\\n",
       "0    0   35     170      75       90.0         1.0          1.0          1   \n",
       "1    0   30     180      80       89.0         0.9          1.2          1   \n",
       "2    0   40     165      75       91.0         1.2          1.5          1   \n",
       "3    0   50     175      80       91.0         1.5          1.2          1   \n",
       "4    0   50     165      60       80.0         1.0          1.2          1   \n",
       "\n",
       "   hear_right  SBP  ...  LDL_chole  triglyceride  hemoglobin  urine_protein  \\\n",
       "0           1  120  ...        126            92        17.1              1   \n",
       "1           1  130  ...        148           121        15.8              1   \n",
       "2           1  120  ...         74           104        15.8              1   \n",
       "3           1  145  ...        104           106        17.6              1   \n",
       "4           1  138  ...        117           104        13.8              1   \n",
       "\n",
       "   serum_creatinine  SGOT_AST  SGOT_ALT  gamma_GTP  SMK_stat_type_cd  DRK_YN  \n",
       "0               1.0        21        35         40                 1       1  \n",
       "1               0.9        20        36         27                 3       0  \n",
       "2               0.9        47        32         68                 1       0  \n",
       "3               1.1        29        34         18                 1       0  \n",
       "4               0.8        19        12         25                 1       0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных для обучения <a id=\"31\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вначале нужно определить, на каких данных будет обучаться модель, а на каких тестироваться. **Традиционный подход** - это разделение исходного набора данных на 3 части (обучение, валидация и тестирование) с пропорции 60/20/20. В данном случае обучающая выборка используется для обучения модели, а валидация и тестирование для получения значения метрики без эффекта переобучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако существует и другой подход к разбиению данных - разделение на 2 части (обучение и тестирование) по правилу 80-20 (80% тренировочный, 20% тестовый). Зачастую данный метод применяется в тех случаях, когда отсутствует достаточное количество данных как в обучающем, так и в проверочном наборе.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед тем как начать разбивать данные необходимо выделить из исходного набора данных целевую переменную (столбец `DRK_YN`) и сохранить её в отдельную переменную. Ниже приведён код разделения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=[\"DRK_YN\"], axis=1)\n",
    "y = df[\"DRK_YN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе выполнения данной работы будет использован подход с разделением исходной выборки на 2 части с пропорцией 80-20, поскольку данный способ является самым популярным способом разбиения данных. Для того, чтобы разбить данные таким образом, существует специальный метод `train_test_split` в библиотеке `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метод к-ближайших соседей <a id=\"331\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Алгоритм KNN** (k-nearest Neighbors) - типичный пример *ленивого ученика*. Ученик называется \"ленивым\" не из-за своей очевидной простоты, а оттого, что он не узнаёт различающую функцию из обучающих данных, а взамен запоминает обучающий набор данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сам алгоритм KNN довольно прямолинеен и может быть подытожен в виде следующих шагов:\n",
    "1) Выбрать число $k$ и метрику расстояния;\n",
    "2) Найти $k$ ближайших соседей образца, который нужно классифицировать;\n",
    "3) Назначить метку класса по большинству голосов.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Базируясь на выбранной метрике расстояния, алгоритм KNN находит в обучающем наборе данных $k$ образцов, ближайших (или наиболее похожих) к точке, которую необходимо классифицировать. Затем метка класса для точки данных определяется на основе мажоритарного голосования среди её $k$ ближайших соседей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главное преимущество такого основанного на памяти подхода в том, что классификатор немедленно адаптируется по мере накопления нами новых обучающих данных. Тем е менее, недостаток связан с тем, что вычислительная сложность классификации новых образцов при худшем сценарии растёт линейно с увеличением количества образцов в обучающем наборе данных. Кроме того, мы не можем отбрасывать обучающие образцы ввиду отсутствия шага *обучения*. Таким образом, при работе с крупными наборами данных проблемой может стать пространство хранения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Правильный* выбор $k$ критически важен для нахождения хорошего баланса между переобучением и недообучением. Также необходимо обеспечить выбор метрики расстояния, подходящей для признаков в наборе данных. Для образцов с вещественными значениями часто применяется простая мера - евклидово расстояние. Однако при использовании меры в виде евклидова расстояния также важно **стандартизировать данные**, чтобы каждый признак в равной степени вносил вклад в расстояние."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее, перейдём к практической части работы с данной моделью, а именно создадим экземпляр данной модели, подберём наилучшую комбинацию гиперпараметров, обучим модель и оценим точность предсказаний. Практическая реализация данной модели находится в библиотеке `scikit-learn`, поэтому импортируем из неё все необходимые компоненты в проект."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что помимо классификационной модели были также импортированы и другие компоненты из данной библиотеки. Таковыми компонентами стали `StandardScaler`, `Pipeline` и `GridSearchCV`. \n",
    "\n",
    "Модуль `preprocessing` в **scikit-learn** предоставляет класс `StandardScaler`, который является быстрым и простым способом стандартизации набора данных. Стандартизация наборов данных является общим требованием для многих моделей машинного обучения, реализованных в **scikit-learn**. Если отдельные признаки не похожи на стандартные нормально-распределённые данные (Гауссовские с нулевым средним значением и единичной дисперсией), то модели могут работать некорректно.\n",
    "\n",
    "Для создания составной модели преобразователи данных обычно объединяются с другими преобразователями или моделями. Преобразователи данных - это алгоритмы, которые изменяют данные, например, `StandardScaler`. Наиболее распространенным инструментом для создания составных моделей является `Pipeline` (или конвейер). Конвейер полезен, поскольку обычно существует фиксированная последовательность шагов при обработке данных, например, выбор признаков => нормализация => классификация.\n",
    "\n",
    "Гиперпараметры - это параметры, которые непосредственно влияют на обучение модели. В **scikit-learn** они передаются в качестве аргументов конструктору класса оценщиков. И для того, чтобы не проверять вручную каждый гиперпараметр у каждой из моделей в **scikit-learn** предусмотрены два общих подхода к поиску параметров: `GridSearchCV` исчерпывающе рассматривает все комбинации параметров, в то время как `RandomizedSearchCV` может выбирать заданное количество кандидатов из пространства параметров с заданным распределением. Но, поскольку `GridSearchCV` может выполнятся достаточно долго, будем использовать более оптимизированную его версию - `HalvingGridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chime\n",
    "%load_ext chime "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее создадим конвейер из двух составляющих: стандартизатора и самого классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем стандартизатор\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "# Создаем классификатор\n",
    "knn = KNeighborsClassifier(n_jobs=-1)\n",
    "\n",
    "# Создаём конвейер\n",
    "pipe = Pipeline([(\"standardizer\", standardizer), (\"knn\", knn)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем, определим гиперпараметры, от которых зависит классификатор и которые будут перебираться в процессе кросс-валидации:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        \"knn__n_neighbors\": np.arange(5, 15),\n",
    "        \"knn__metric\": [\"minkowski\", \"euclidean\", \"manhattan\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим процесс кросс-валидации и выведем наилучшую комбинацию гиперпараметров для данного классификатора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 29372\n",
      "max_resources_: 793048\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 30\n",
      "n_resources: 29372\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 10\n",
      "n_resources: 88116\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 4\n",
      "n_resources: 264348\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 2\n",
      "n_resources: 793044\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "CPU times: total: 2.61 s\n",
      "Wall time: 2h 34min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%chime\n",
    "knn_classifier = HalvingGridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=params,\n",
    "    factor=3,\n",
    "    cv=5, verbose=1,\n",
    "    n_jobs=-3,\n",
    "    scoring=\"roc_auc\").fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После завершения подбора параметров посмотрим на наилучшую их комбинацию, а также наилучшую оценку, полученную на тренировочных данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальные параметры: {'knn__metric': 'manhattan', 'knn__n_neighbors': 14}\n",
      "Наилучшая оценка: 0.7822574017077157\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Оптимальные параметры: {knn_classifier.best_params_}\\nНаилучшая оценка: {knn_classifier.best_score_}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимальные параметры: {'knn__metric': 'manhattan', 'knn__n_neighbors': 14}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
