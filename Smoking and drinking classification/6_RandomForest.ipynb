{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Содержание\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Создание и обучение модели](#3)\n",
    "    - [Подготовка данных для обучения](#31)\n",
    "    - [Ансамблевые модели: беггинг](#335)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание и обучение модели <a id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_dataset.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>waistline</th>\n",
       "      <th>sight_left</th>\n",
       "      <th>sight_right</th>\n",
       "      <th>hear_left</th>\n",
       "      <th>hear_right</th>\n",
       "      <th>SBP</th>\n",
       "      <th>...</th>\n",
       "      <th>LDL_chole</th>\n",
       "      <th>triglyceride</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>urine_protein</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>SGOT_AST</th>\n",
       "      <th>SGOT_ALT</th>\n",
       "      <th>gamma_GTP</th>\n",
       "      <th>SMK_stat_type_cd</th>\n",
       "      <th>DRK_YN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>170</td>\n",
       "      <td>75</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>126</td>\n",
       "      <td>92</td>\n",
       "      <td>17.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>148</td>\n",
       "      <td>121</td>\n",
       "      <td>15.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>165</td>\n",
       "      <td>75</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>104</td>\n",
       "      <td>15.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>47</td>\n",
       "      <td>32</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>106</td>\n",
       "      <td>17.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>165</td>\n",
       "      <td>60</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>104</td>\n",
       "      <td>13.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  age  height  weight  waistline  sight_left  sight_right  hear_left  \\\n",
       "0    0   35     170      75       90.0         1.0          1.0          1   \n",
       "1    0   30     180      80       89.0         0.9          1.2          1   \n",
       "2    0   40     165      75       91.0         1.2          1.5          1   \n",
       "3    0   50     175      80       91.0         1.5          1.2          1   \n",
       "4    0   50     165      60       80.0         1.0          1.2          1   \n",
       "\n",
       "   hear_right  SBP  ...  LDL_chole  triglyceride  hemoglobin  urine_protein  \\\n",
       "0           1  120  ...        126            92        17.1              1   \n",
       "1           1  130  ...        148           121        15.8              1   \n",
       "2           1  120  ...         74           104        15.8              1   \n",
       "3           1  145  ...        104           106        17.6              1   \n",
       "4           1  138  ...        117           104        13.8              1   \n",
       "\n",
       "   serum_creatinine  SGOT_AST  SGOT_ALT  gamma_GTP  SMK_stat_type_cd  DRK_YN  \n",
       "0               1.0        21        35         40                 1       1  \n",
       "1               0.9        20        36         27                 3       0  \n",
       "2               0.9        47        32         68                 1       0  \n",
       "3               1.1        29        34         18                 1       0  \n",
       "4               0.8        19        12         25                 1       0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом шаге происходит обучение модели. Обучение моделей машинного обучения происходит итерационно - пробуются различные модели, перебираются гиперпараметры, сравниваются значения выбранной метрики и выбирается лучшая комбинация.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных для обучения <a id=\"31\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вначале нужно определить, на каких данных будет обучаться модель, а на каких тестироваться. **Традиционный подход** - это разделение исходного набора данных на 3 части (обучение, валидация и тестирование) с пропорции 60/20/20. В данном случае обучающая выборка используется для обучения модели, а валидация и тестирование для получения значения метрики без эффекта переобучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако существует и другой подход к разбиению данных - разделение на 2 части (обучение и тестирование) по правилу 80-20 (80% тренировочный, 20% тестовый). Зачастую данный метод применяется в тех случаях, когда отсутствует достаточное количество данных как в обучающем, так и в проверочном наборе.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед тем как начать разбивать данные необходимо выделить из исходного набора данных целевую переменную (столбец `DRK_YN`) и сохранить её в отдельную переменную. Ниже приведён код разделения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=[\"DRK_YN\"], axis=1)\n",
    "y = df[\"DRK_YN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе выполнения данной работы будет использован подход с разделением исходной выборки на 2 части с пропорцией 80-20, поскольку данный способ является самым популярным способом разбиения данных. Для того, чтобы разбить данные таким образом, существует специальный метод `train_test_split` в библиотеке `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ансамблевые модели: беггинг <a id=\"335\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У каждой модели машинного обучения есть некоторый предел, до которого можно повышать точность, а дальше начинается переобучение и модель уже физически не может предсказать точнее, чем заложено в её природе. Эта природа определяется не только моделью, а связкой модели, т.е. математическим аппаратом и данными, которые эта модель пытается преобразовать. Однако точность работы одной конкретной модели не является пределом при решении задач машинного обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда с этим столкнулись первые исследователи они обратились к математической статистике и выяснили, что если взять несколько однородных моделей и среднее их предсказание, но при этом модели обучены на немного разных выборках, то получится, что ошибка среднего равна $\\sqrt{n}$, где $n$ это количество моделей. И ошибка выходит меньше за счёт того, что мы берём несколько одинаковых моделей. **Цель** ансамблевых методов - объединить различные классификаторы в метаклассификатор, который обладает лучшей эффективностью обобщения, чем каждый индивидуальный классификатор сам по себе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве примера ансамблей можно привести феномен \"Мудрость толпы\". В 1906 году Френсис Гальтон предлагал посетителям ярмарки угадать вес живого быка. Всего в эксперименте приняли участие около 800 человек. Каждый из участников должен был написать свой ответ на карточке и передать её Гальтону. Затем он сложил все ответы и разделил их на общее количество участников, чтобы получить среднее значение. Результат оказался удивительным: среднее значение всех ответов было ближе к истинному весу быка, чем большинство индивидуальных ответов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наиболее популярными видами ансамблирования являются:\n",
    "1. **Бэггинг** (bagging: bootstrap aggregation) - принцип построения композиции, основанный на простом голосовании.\n",
    "2. **Бустинг** - принцип построения композиции, основанный на последовательном обучении моделей, при котором модели исправляют ошибки друг у друга.\n",
    "3. **Стекинг** - принцип, при котором происходит комбинация разнородных моделей для построения прогноза."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Бэггинг** *(bootstrap aggregating)* - это метод, который позволяет уменьшить вариабельность модели, увеличивая её точность. Основная идея бэггинга заключается в том, чтобы обучить несколько одинаковых моделей на разных образцах. Затем результаты этих моделей объединяются для получения окончательного прогноза. Поскольку изначальное распределение выборки неизвестно, то модели получаются разными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Один из самых известных примеров использования техники беггинга в алгоритмах машинного обучения - это **случайный лес**. Он представляет собой набор деревьев принятия решений. Основная идея случайного леса заключается в усреднении результатов множества деревьев, каждое из которых может иметь высокую дисперсию. Алгоритм случайного леса можно описать в виде следующих шагов:\n",
    "1. Создаем случайную бутстрэп-выборку размером *n* (случайно выбрать *n* образцов из обучающего набора с возвращением);\n",
    "2. Строим дерево принятия решений на основе этой выборки. В каждом узле:\n",
    "    a) выбираем d признаков случайным образом без возможности возвращения;\n",
    "    b) разделяем узел, используя признак, который обеспечивает наилучшее разделение согласно целевой функции, максимизирующей Information Gain;\n",
    "3. Повторяем шаги 1 и 2 *k* раз.\n",
    "4. Объединить прогнозы всех деревьев путем назначения метки класса по большинству голосов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее перейдём к практической реализации и создадим модель случайного леса используя библиотеку `sklearn`. Также, проведём тюнинг гиперпараметров данной модели при помощи кросс-валидации. Для начала импортируем все необходимые библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chime extension is already loaded. To reload it, use:\n",
      "  %reload_ext chime\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "import chime\n",
    "%load_ext chime "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перекрёстная проверка (или же кросс-валидация) производится по следующей причине: \n",
    "\n",
    "Каждое дерево (по умолчанию из 100) строится на своей части выборки наборов параметров (max_features). Решение принимается путём голосования деревьев.\n",
    "\n",
    "Например, 10 деревьев для одной строки исходных данных дали следующие классы и вероятности:\n",
    "\n",
    "{1:0.5, 1:0.8, 2:0.9, 3:0.7, 5:0.5, 1:0.4, 2:0.5, 6:0.5, 3:0.4, 1:0.95}\n",
    "\n",
    "По итогам голосования выбирается самый популярный класс, это 1 в данном случае.\n",
    "\n",
    "Если в случайном лесу слишком много деревьев, то точность предсказания будет меньше, чем у одного, полностью обученного дерева. Число деревьев (estimators) должно соответствовать количеству классов в предсказании (class), размеру выборки (N) и числу разбиений (fold). Примерная формула: estimators = N / (20...100) / fold / class.\n",
    "\n",
    "В данном случае N = 793048, fold = 5, class = 2 => estimators = 793...3965"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее, также как и в предыдущий раз, создадим конвейер из двух составляющих: стандартизатора и самого классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем стандартизатор\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "# Создаем классификатор\n",
    "forest = RandomForestClassifier(n_jobs=-1, n_estimators=793)\n",
    "\n",
    "# Создаём конвейер\n",
    "pipe = Pipeline([(\"standardizer\", standardizer), (\"forest\", forest)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Диапазон тестирования параметров модели ограничен лишь вычислительной мощностью. Поэтому определим набор параметров, которые будут проверятся при кросс-валидации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"forest__max_depth\": range(13, 15),\n",
    "    \"forest__max_features\": range(10, 18),\n",
    "    \"forest__min_samples_leaf\": range(17, 20),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим процесс валидации и выведем оптимальные параметры для данного классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 29372\n",
      "max_resources_: 793048\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 48\n",
      "n_resources: 29372\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 16\n",
      "n_resources: 88116\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 6\n",
      "n_resources: 264348\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 2\n",
      "n_resources: 793044\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "CPU times: total: 1h 18min 45s\n",
      "Wall time: 1h 52min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%chime\n",
    "forest_classifier = HalvingGridSearchCV(\n",
    "    estimator=pipe, \n",
    "    param_grid=params,\n",
    "    factor=3,\n",
    "    cv=5, verbose=1, \n",
    "    n_jobs=-3, \n",
    "    scoring=\"roc_auc\").fit(\n",
    "    x_train, y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После завершения этапа обучения выведем наилучшую комбинацию параметров, а также наилучшую оценку, полученную на тренировочных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(forest_classifier.cv_results_)\n",
    "results[\"params_str\"] = results.params.apply(str)\n",
    "results.drop_duplicates(subset=(\"params_str\", \"iter\"), inplace=True)\n",
    "mean_scores = results.pivot(\n",
    "    index=\"iter\", columns=\"params_str\", values=\"mean_test_score\"\n",
    ")\n",
    "ax = mean_scores.plot(legend=False, alpha=0.6)\n",
    "labels = [\n",
    "    f\"iter={i}\\nn_samples={forest_classifier.n_resources_[i]}\\nn_candidates={forest_classifier.n_candidates_[i]}\"\n",
    "    for i in range(forest_classifier.n_iterations_)\n",
    "]\n",
    "ax.set_xticks(range(forest_classifier.n_iterations_))\n",
    "ax.set_xticklabels(labels, rotation=45, multialignment=\"left\")\n",
    "ax.set_title(\"Оценка всех кандидатов по итерациям\")\n",
    "ax.set_ylabel(\"средний тестовый результат\")\n",
    "ax.set_xlabel(\"итерации\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальные параметры: {'forest__max_depth': 14, 'forest__max_features': 11, 'forest__min_samples_leaf': 17}\n",
      "Наилучшая оценка: 81.84%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Оптимальные параметры: {forest_classifier.best_params_}\\nНаилучшая оценка: {forest_classifier.best_score_:.2%}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимальные параметры: {'forest__max_depth': 14, 'forest__max_features': 10, 'forest__min_samples_leaf': 17}\n",
    "Наилучшая оценка: 81.81%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
