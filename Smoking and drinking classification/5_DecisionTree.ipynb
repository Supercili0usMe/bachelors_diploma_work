{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Содержание\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Создание и обучение модели](#3)\n",
    "    - [Подготовка данных для обучения](#31)\n",
    "    - [Обучение моделей](#33)\n",
    "        - [Деревья решений](#334)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание и обучение модели <a id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_dataset.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>waistline</th>\n",
       "      <th>sight_left</th>\n",
       "      <th>sight_right</th>\n",
       "      <th>hear_left</th>\n",
       "      <th>hear_right</th>\n",
       "      <th>SBP</th>\n",
       "      <th>...</th>\n",
       "      <th>LDL_chole</th>\n",
       "      <th>triglyceride</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>urine_protein</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>SGOT_AST</th>\n",
       "      <th>SGOT_ALT</th>\n",
       "      <th>gamma_GTP</th>\n",
       "      <th>SMK_stat_type_cd</th>\n",
       "      <th>DRK_YN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>170</td>\n",
       "      <td>75</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>126</td>\n",
       "      <td>92</td>\n",
       "      <td>17.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>...</td>\n",
       "      <td>148</td>\n",
       "      <td>121</td>\n",
       "      <td>15.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>165</td>\n",
       "      <td>75</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>104</td>\n",
       "      <td>15.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>47</td>\n",
       "      <td>32</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>106</td>\n",
       "      <td>17.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>165</td>\n",
       "      <td>60</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>104</td>\n",
       "      <td>13.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  age  height  weight  waistline  sight_left  sight_right  hear_left  \\\n",
       "0    0   35     170      75       90.0         1.0          1.0          1   \n",
       "1    0   30     180      80       89.0         0.9          1.2          1   \n",
       "2    0   40     165      75       91.0         1.2          1.5          1   \n",
       "3    0   50     175      80       91.0         1.5          1.2          1   \n",
       "4    0   50     165      60       80.0         1.0          1.2          1   \n",
       "\n",
       "   hear_right  SBP  ...  LDL_chole  triglyceride  hemoglobin  urine_protein  \\\n",
       "0           1  120  ...        126            92        17.1              1   \n",
       "1           1  130  ...        148           121        15.8              1   \n",
       "2           1  120  ...         74           104        15.8              1   \n",
       "3           1  145  ...        104           106        17.6              1   \n",
       "4           1  138  ...        117           104        13.8              1   \n",
       "\n",
       "   serum_creatinine  SGOT_AST  SGOT_ALT  gamma_GTP  SMK_stat_type_cd  DRK_YN  \n",
       "0               1.0        21        35         40                 1       1  \n",
       "1               0.9        20        36         27                 3       0  \n",
       "2               0.9        47        32         68                 1       0  \n",
       "3               1.1        29        34         18                 1       0  \n",
       "4               0.8        19        12         25                 1       0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом шаге происходит обучение модели. Обучение моделей машинного обучения происходит итерационно - пробуются различные модели, перебираются гиперпараметры, сравниваются значения выбранной метрики и выбирается лучшая комбинация.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных для обучения <a id=\"31\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вначале нужно определить, на каких данных будет обучаться модель, а на каких тестироваться. **Традиционный подход** - это разделение исходного набора данных на 3 части (обучение, валидация и тестирование) с пропорции 60/20/20. В данном случае обучающая выборка используется для обучения модели, а валидация и тестирование для получения значения метрики без эффекта переобучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако существует и другой подход к разбиению данных - разделение на 2 части (обучение и тестирование) по правилу 80-20 (80% тренировочный, 20% тестовый). Зачастую данный метод применяется в тех случаях, когда отсутствует достаточное количество данных как в обучающем, так и в проверочном наборе.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед тем как начать разбивать данные необходимо выделить из исходного набора данных целевую переменную (столбец `DRK_YN`) и сохранить её в отдельную переменную. Ниже приведён код разделения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=[\"DRK_YN\"], axis=1)\n",
    "y = df[\"DRK_YN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе выполнения данной работы будет использован подход с разделением исходной выборки на 2 части с пропорцией 80-20, поскольку данный способ является самым популярным способом разбиения данных. Для того, чтобы разбить данные таким образом, существует специальный метод `train_test_split` в библиотеке `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Деревья решений <a id=\"334\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классификаторы на основе **деревьев принятия решений** являются привлекательными моделями, когда необходима интерпретируемость данных. Как подсказывает само название, можно предположить, что такая модель разбивает данные, задавая последовательность вопросов. Базируясь на признаках в обучающем наборе, модель на основе дерева принятия решений обучается последовательности вопросов, чтобы выводить метки классов для образцов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя алгоритм принятия решения, начинаем с корня дерева и разбиваем данные по признаку, который дает в результате наибольший *прирост информации (Information Gain)*. В рамках итерационного процесса повторяем описанную процедуру разбиения в каждом узле, пока листовые узлы не станут чистыми. Это означает, что все образцы в каждом узле принадлежат тому же самому классу.\n",
    "\n",
    "На практике результатом может оказаться очень глубокое дерево с многочисленными узлами, что легко способно привести к переобучению. Таким образом, дерево необходимо *подрезать*, устанавливая предел для его максимальной глубины."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы разделить узлы в самых информативных признаках, нам понадобится определить целевую функцию, которую необходимо оптимизировать посредством алгоритма обучения дерева. В данном случае целевая функция заключается в доведении до максимума прироста информации при каждом разделении, что определяется следующим образом:\n",
    "$$IG(D_p, f) = I(D_p) - \\sum_{j=1}^n \\frac{N_j}{N_p}I(D_j)$$\n",
    "где: $f$ - признак для выполнения разбиения; $D_p$ и $D_j$ - набор данных родительского и $j$-ого дочернего узла; $I$ - мера загрязнённости; $N_p$ - общее количество образцов в родительском узле; $N_j$ - количество образцов в $j$-ом дочернем узле."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что прирост информации представляет собой просто разность между загрязнённостью родительского узла и суммой загрязнённостей дочерних узлов - чем ниже загрязнённость дочерних узлов, тем выше прирост информации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зачастую применяют следующие 3 меры загрязнённости (или критерии разбиения):\n",
    "1. **Энтропия ($I_H$)**:\n",
    "$$I_H(t) = - \\sum_{i=1}^c p(i|t) \\ \\log_2 p(i|t)$$\n",
    "В данном случае $p(i|t)$ - доля образцов, которые принадлежат классу $i$ для индивидуального узла $t$. </br>\n",
    "Следовательно, энтропия равна $0$, если все образцы в узле принадлежат тому же самому классу, и максимальна при равномерном распределении классов. Таким образом, можно говорить, что критерий энтропии стремится довести до максимума полное количество информации в дереве.\n",
    "\n",
    "2. **Критерий Джинни ($I_G$)**:\n",
    "\n",
    "Загрязнённость Джинни можно понимать как критерий для минимизации вероятности неправильной классификации:\n",
    "$$I_G(t) = \\sum_{i=1}^c p(i|t)(1-p(i|t)) = 1 - \\sum_{i=1}^c p(i|t)^2$$ \n",
    "Подобно энтропии критерий Джинни максимален, когда классы в полной мере перемешаны, например, в окружении с двоичным классами. Тем не менее, на практике загрязненность Джинни и энтропия выдают очень похожие результаты, и часто не стоит тратить много времени на оценку деревьев с использованием различных критериев загрязнённости вместо экспериментирования с разными параметрами отсечения при подрезке.\n",
    "\n",
    "3. **Ошибка классификации ($I_{\\Epsilon}$)**:\n",
    "\n",
    "$$I_{\\Epsilon} = 1 - max(p(i|t))$$\n",
    "Ошибка классификации - полезный критерий для подрезки, но не рекомендуется для создания дерева принятия решений, т.к. она менее чувствительна к изменениям в вероятностях классов узлов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее, попробуем построить несколько моделей дерева решений и найдем оптимальную через кросс-валидацию. Перед началом выполнения поставленной задачи - импортируем все необходимые модули:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Categorical, Real, Integer\n",
    "import chime\n",
    "%load_ext chime "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее, также как и в предыдущий раз, создадим конвейер из двух составляющих: стандартизатора и самого классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем стандартизатор\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "# Создаем классификатор\n",
    "tree = DecisionTreeClassifier(min_samples_leaf=10)\n",
    "\n",
    "# Создаём конвейер\n",
    "pipe = Pipeline([(\"standardizer\", standardizer), (\"tree\", tree)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и в предыдущие разы, определим гиперпараметры, от которых зависит классификатор и которые будут перебираться в процессе кросс-валидации:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"tree__criterion\": Categorical([\"gini\", \"entropy\", \"log_loss\"]),\n",
    "    \"tree__max_depth\": Integer(10, 20),\n",
    "    \"tree__max_features\": Integer(1, len(x_train.columns)),\n",
    "    \"tree__min_samples_leaf\": Integer(20, 50),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим процесс кросс-валидации и выведем наилучшую комбинацию гиперпараметров для данного классификатора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "CPU times: total: 29.5 s\n",
      "Wall time: 5min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%chime\n",
    "tree_classifier = BayesSearchCV(\n",
    "    estimator=pipe, \n",
    "    search_spaces=params,\n",
    "    cv=5, verbose=1, \n",
    "    n_jobs=-3, \n",
    "    scoring=\"roc_auc\").fit(\n",
    "    x_train, y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После завершения подбора параметров посмотрим на наилучшую их комбинацию, а также наилучшую оценку, полученную на тренировочных данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальные параметры: OrderedDict([('tree__criterion', 'log_loss'), ('tree__max_depth', 10), ('tree__max_features', 23), ('tree__min_samples_leaf', 50)])\n",
      "Наилучшая оценка: 0.8059523169995811\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Оптимальные параметры: {tree_classifier.best_params_}\\nНаилучшая оценка: {tree_classifier.best_score_}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимальные параметры: OrderedDict([('tree__criterion', 'log_loss'), ('tree__max_depth', 10), ('tree__max_features', 23), ('tree__min_samples_leaf', 50)])\n",
    "Наилучшая оценка: 0.8059523169995811"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
